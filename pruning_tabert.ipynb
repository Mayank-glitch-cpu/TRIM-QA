{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u7WCgrEJ2h5p",
    "outputId": "61678c85-03f3-44c0-abd8-48acf26594b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /home/itewari1/.local/lib/python3.12/site-packages (4.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/itewari1/.local/lib/python3.12/site-packages (from sentence-transformers) (4.51.2)\n",
      "Requirement already satisfied: tqdm in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/itewari1/.local/lib/python3.12/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /home/itewari1/.local/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/itewari1/.local/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/itewari1/.local/lib/python3.12/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/itewari1/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/itewari1/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/itewari1/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/itewari1/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/itewari1/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/itewari1/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/itewari1/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/itewari1/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/itewari1/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/itewari1/.local/lib/python3.12/site-packages (4.51.2)\n",
      "Requirement already satisfied: filelock in /home/itewari1/.local/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/itewari1/.local/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/itewari1/.local/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/itewari1/.local/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/itewari1/.local/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/itewari1/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /packages/apps/jupyter/2025-03-24/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Xw-sWTvY2fKk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer, BertModel, TapasTokenizer, TapasForSequenceClassification\n",
    "import jsonlines\n",
    "import time\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from typing import List, Dict\n",
    "\n",
    "# Set tokenizers parallelism to avoid warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Hlp6FkYbajod",
    "outputId": "63819641-02e6-4a73-fe63-a97bcd0de467"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load once (simulate TaBERT-style scoring)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BbwescLcUEqv"
   },
   "outputs": [],
   "source": [
    "def fetch_chunks(table_id):\n",
    "  # Read chunks from chunks.json that match the target table\n",
    "    print(\"Loading and filtering chunks for target table...\")\n",
    "    # chunks = []\n",
    "    row_chunks = []\n",
    "    column_chunks = []\n",
    "    chunk_count = 0\n",
    "    matched_chunks = 0\n",
    "\n",
    "    with jsonlines.open('chunks.json', 'r') as reader:\n",
    "        for chunk in reader:\n",
    "            chunk_count += 1\n",
    "\n",
    "            # Check if the chunk belongs to our target table or any of its alternative IDs\n",
    "            if 'metadata' in chunk and 'table_name' in chunk['metadata'] and chunk['metadata']['table_name'] in table_id:\n",
    "                # chunks.append(chunk)\n",
    "                if chunk['metadata']['chunk_type'] == 'row':\n",
    "                    row_chunks.append(chunk)\n",
    "                else:\n",
    "                    column_chunks.append(chunk)\n",
    "                matched_chunks += 1\n",
    "\n",
    "    print(f\"Found {matched_chunks} chunks that match table ID '{table_id}' out of {chunk_count} total chunks\")\n",
    "\n",
    "    return row_chunks, column_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rwBHNQSdPXzJ"
   },
   "outputs": [],
   "source": [
    "def score_column_chunks_tabert(query: str, column_chunks: List[Dict]):\n",
    "    \"\"\"\n",
    "    Compute semantic similarity between a query and each column chunk using [CLS] embedding similarity,\n",
    "    with support for GPU via device argument.\n",
    "\n",
    "    Args:\n",
    "        query (str): Natural language query.\n",
    "        column_chunks (List[Dict]): List of column chunks in your format.\n",
    "        device (torch.device): torch.device(\"cuda\") or torch.device(\"cpu\")\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, float]]: [(column_name, similarity_score)]\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encode query and move to device\n",
    "        query_inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        query_inputs = {k: v.to(device) for k, v in query_inputs.items()}\n",
    "        query_output = model(**query_inputs)\n",
    "        query_vec = query_output.last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        for chunk in column_chunks:\n",
    "            col_text = chunk.get(\"text\", \"\")\n",
    "            metadata_text = chunk.get(\"metadata\", {}).get(\"metadata_text\", \"\")\n",
    "            col_name = \"\"\n",
    "\n",
    "            for part in metadata_text.split(','):\n",
    "                if part.strip().startswith(\"col:\"):\n",
    "                    col_name = part.strip().replace(\"col:\", \"\").strip()\n",
    "                    break\n",
    "\n",
    "            col_inputs = tokenizer(col_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "            col_inputs = {k: v.to(device) for k, v in col_inputs.items()}\n",
    "            col_output = model(**col_inputs)\n",
    "            col_vec = col_output.last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "            sim = torch.nn.functional.cosine_similarity(query_vec, col_vec).item()\n",
    "            sim = round((sim + 1) / 2, 4)  # Normalize to [0, 1]\n",
    "\n",
    "            results.append((col_name, sim))\n",
    "\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qXYk97pfWnnG"
   },
   "outputs": [],
   "source": [
    "def filter_chunks_by_column_score(chunks, scored_columns, threshold):\n",
    "    \"\"\"\n",
    "    Filters column chunks from the list of chunks based on precomputed SBERT scores.\n",
    "\n",
    "    Args:\n",
    "        chunks (list): List of all chunk dictionaries.\n",
    "        scored_columns (list of tuples): List of (column_name, score) tuples from SBERT.\n",
    "        threshold (float): Minimum score required to retain a chunk.\n",
    "\n",
    "    Returns:\n",
    "        filtered_chunks (list): Chunks whose column name score >= threshold.\n",
    "    \"\"\"\n",
    "    # Build a set of column names to keep\n",
    "    valid_columns = {col for col, score in scored_columns if score >= threshold}\n",
    "\n",
    "    # Filter chunks that are 'column' type and have a matching valid column name\n",
    "    filtered_chunks = []\n",
    "    for chunk in chunks:\n",
    "        metadata_text = chunk[\"metadata\"].get(\"metadata_text\", \"\")\n",
    "        for part in metadata_text.split(','):\n",
    "            part = part.strip()\n",
    "            if part.startswith(\"col:\"):\n",
    "                col_name = part.replace(\"col:\", \"\").strip()\n",
    "                if col_name in valid_columns:\n",
    "                    filtered_chunks.append(chunk)\n",
    "                break\n",
    "\n",
    "    return filtered_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "e3bfjzKNPXzK"
   },
   "outputs": [],
   "source": [
    "def score_row_chunks_tabert(query: str, row_chunks: List[Dict]):\n",
    "    \"\"\"\n",
    "    Compute semantic similarity between a query and each row chunk using [CLS] embedding similarity.\n",
    "\n",
    "    Args:\n",
    "        query (str): Natural language query.\n",
    "        row_chunks (List[Dict]): List of row chunks in your format.\n",
    "        device (torch.device): torch.device(\"cuda\") or torch.device(\"cpu\")\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: [{\"chunk_id\": ..., \"score\": ...}]\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Tokenize and move query to device\n",
    "        query_inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        query_inputs = {k: v.to(device) for k, v in query_inputs.items()}\n",
    "        query_output = model(**query_inputs)\n",
    "        query_vec = query_output.last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        for chunk in row_chunks:\n",
    "            row_text = chunk.get(\"text\", \"\")\n",
    "            chunk_id = chunk.get(\"metadata\", {}).get(\"chunk_id\", \"\")\n",
    "\n",
    "            row_inputs = tokenizer(row_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "            row_inputs = {k: v.to(device) for k, v in row_inputs.items()}\n",
    "            row_output = model(**row_inputs)\n",
    "            row_vec = row_output.last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "            sim = torch.nn.functional.cosine_similarity(query_vec, row_vec).item()\n",
    "            sim = round((sim + 1) / 2, 4)  # Normalize to [0, 1]\n",
    "\n",
    "            results.append({\n",
    "                \"chunk_id\": chunk_id,\n",
    "                \"score\": sim\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tbHi6m9Hfyiu"
   },
   "outputs": [],
   "source": [
    "def filter_chunks_by_row_score(chunks, scored_rows, threshold):\n",
    "    \"\"\"\n",
    "    Filters row chunks from the list of chunks based on precomputed semantic similarity scores.\n",
    "\n",
    "    Args:\n",
    "        chunks (list): List of all chunk dictionaries (from chunk_row).\n",
    "        scored_rows (list of dict): List of {'chunk_id': str, 'score': float} dicts.\n",
    "        threshold (float): Minimum score required to retain a chunk.\n",
    "\n",
    "    Returns:\n",
    "        filtered_chunks (list): Chunks whose score >= threshold.\n",
    "    \"\"\"\n",
    "    # Build a set of valid chunk_ids to retain\n",
    "    valid_ids = {row['chunk_id'] for row in scored_rows if row['score'] >= threshold}\n",
    "\n",
    "    # Filter chunks based on matching chunk_id\n",
    "    filtered_chunks = [\n",
    "        chunk for chunk in chunks\n",
    "        if chunk['metadata']['chunk_id'] in valid_ids\n",
    "    ]\n",
    "\n",
    "    return filtered_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Gt8YjloYPXzK"
   },
   "outputs": [],
   "source": [
    "def dynamic_threshold(scores, alpha):\n",
    "    \"\"\"\n",
    "    Calculate a dynamic threshold using mean + alpha * std deviation.\n",
    "\n",
    "    Args:\n",
    "        scores (list or np.array): List of similarity scores (floats between 0 and 1).\n",
    "        alpha (float): Multiplier for standard deviation (default 0.5).\n",
    "\n",
    "    Returns:\n",
    "        float: Threshold value\n",
    "    \"\"\"\n",
    "    # alpha = adaptive_alpha(scores)\n",
    "    # scores = np.array(scores)\n",
    "\n",
    "    # if len(scores) == 0:\n",
    "    #     raise ValueError(\"Score list is empty.\")\n",
    "\n",
    "    # mean = np.mean(scores)\n",
    "    # std_dev = np.std(scores)\n",
    "    # threshold = mean + alpha * std_dev\n",
    "\n",
    "    # return threshold\n",
    "    median = np.median(scores)\n",
    "    std_dev = np.std(scores)\n",
    "    return median + alpha * std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "J149T_wRhCeY"
   },
   "outputs": [],
   "source": [
    "def column_chunks_to_dataframe(column_chunks):\n",
    "    \"\"\"\n",
    "    Converts a list of column chunks into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        column_chunks (list): List of chunks, each containing a column in 'text' and metadata.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Structured DataFrame with headers and rows.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "\n",
    "    for chunk in column_chunks:\n",
    "        text = chunk.get(\"text\", \"\")\n",
    "\n",
    "        # Only process if the format is correct\n",
    "        if \":\" in text:\n",
    "            header, values_str = text.split(\":\", 1)\n",
    "            header = header.strip()\n",
    "\n",
    "            if not header:\n",
    "                continue\n",
    "\n",
    "            # Split values and remove empty strings\n",
    "            values = [v.strip() for v in values_str.strip().split(\"|\") if v.strip()]\n",
    "            data[header] = values\n",
    "\n",
    "    # Normalize column lengths by padding with empty strings\n",
    "    max_len = max((len(vals) for vals in data.values()), default=0)\n",
    "    for header, values in data.items():\n",
    "        if len(values) < max_len:\n",
    "            values.extend([\"\"] * (max_len - len(values)))\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame.from_dict(data, orient='columns')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "l3LLgCS1hHu0"
   },
   "outputs": [],
   "source": [
    "def row_chunks_to_dataframe(row_chunks):\n",
    "    \"\"\"\n",
    "    Converts row-based chunks with inline 'Header: Value' format into a structured DataFrame.\n",
    "\n",
    "    Args:\n",
    "        row_chunks (list): List of row-type chunk dicts.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Structured table with one row per chunk and appropriate columns.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    all_columns = set()\n",
    "\n",
    "    for chunk in row_chunks:\n",
    "        text = chunk.get(\"text\", \"\")\n",
    "        column_names = chunk.get(\"metadata\", {}).get(\"columns\", [])\n",
    "        row_data = dict.fromkeys(column_names, \"\")  # initialize with empty strings\n",
    "\n",
    "        # Split on pipe and extract 'key: value' pairs\n",
    "        for part in text.split(\"|\"):\n",
    "            if \":\" in part:\n",
    "                key, value = part.split(\":\", 1)\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "                if key in column_names:\n",
    "                    row_data[key] = value\n",
    "\n",
    "        rows.append(row_data)\n",
    "        all_columns.update(column_names)\n",
    "\n",
    "    # Build DataFrame with all columns\n",
    "    df = pd.DataFrame(rows, columns=sorted(all_columns))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wzYHWrI4hN3x"
   },
   "outputs": [],
   "source": [
    "def intersect_row_and_column_dfs(df_row, df_col):\n",
    "    \"\"\"\n",
    "    Computes row-wise intersection between a row-based DataFrame and a column-based DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df_row (pd.DataFrame): DataFrame constructed from row chunks.\n",
    "        df_col (pd.DataFrame): DataFrame constructed from column chunks.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Rows common to both DataFrames (intersection).\n",
    "    \"\"\"\n",
    "    # Align columns\n",
    "    common_cols = sorted(set(df_row.columns).intersection(set(df_col.columns)))\n",
    "    if not common_cols:\n",
    "        print(\"⚠️ No overlapping columns found between the DataFrames.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_row_sub = df_row[common_cols].copy()\n",
    "    df_col_sub = df_col[common_cols].copy()\n",
    "\n",
    "    # Drop NA to avoid mismatch due to missing values\n",
    "    df_row_sub = df_row_sub.dropna()\n",
    "    df_col_sub = df_col_sub.dropna()\n",
    "\n",
    "    # Deduplicate if necessary\n",
    "    df_row_sub = df_row_sub.drop_duplicates()\n",
    "    df_col_sub = df_col_sub.drop_duplicates()\n",
    "\n",
    "    # Perform intersection\n",
    "    intersected = pd.merge(df_row_sub, df_col_sub, how='inner')\n",
    "\n",
    "    return intersected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QcHxPCXBPXzL"
   },
   "outputs": [],
   "source": [
    "def dataframe_to_json_entry(df, table_id):\n",
    "    \"\"\"\n",
    "    Convert a pandas DataFrame into a JSON-serializable dict matching the required format.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The pruned table.\n",
    "        table_id (str): Unique table identifier.\n",
    "\n",
    "    Returns:\n",
    "        dict: A JSON-compatible dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    json_entry = {\n",
    "        \"id\": table_id,\n",
    "        \"table\": {\n",
    "            \"columns\": [{\"text\": str(col)} for col in df.columns],\n",
    "            \"rows\": [{\"cells\": [{\"text\": str(cell)} for cell in row]} for _, row in df.iterrows()],\n",
    "            \"tableId\": table_id,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return json_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "q29_B1N-PXzL"
   },
   "outputs": [],
   "source": [
    "def prune_table(table_id, question):\n",
    "    ### Fetch chunks for the given table ID ###\n",
    "    row_chunks, column_chunks = fetch_chunks(table_id)\n",
    "    columns_df = column_chunks_to_dataframe(column_chunks)\n",
    "    row_df = row_chunks_to_dataframe(row_chunks)\n",
    "    # print(\"Column DF:\", columns_df)\n",
    "    # print(\"Row DF:\", row_df)\n",
    "\n",
    "    ### Column Level Pruning ###\n",
    "    # column_headers_with_values = fetch_column_headers_with_values(column_chunks)\n",
    "\n",
    "    # column_scores = score_column_headers_sbert(question, column_headers)\n",
    "    # column_scores = score_column_headers_with_tapas(question, column_headers_with_values)\n",
    "    column_scores = score_column_chunks_tabert(question, column_chunks)\n",
    "    for col, score in column_scores:\n",
    "        print(f\"  {col:15s} → {score:.4f}\")\n",
    "\n",
    "    # print(f\"Relevance score for table: {column_scores:.4f}\")\n",
    "\n",
    "    column_scores_only = [score for _, score in column_scores]\n",
    "    alpha = -0.2 #check if this can be learned\n",
    "    column_threshold = dynamic_threshold(column_scores_only, alpha)\n",
    "    print(\"Column Threshold:\", column_threshold)\n",
    "\n",
    "    filtered_column_chunks = filter_chunks_by_column_score(column_chunks, column_scores, column_threshold)\n",
    "    # print(filtered_column_chunks)\n",
    "\n",
    "    ### Row level Pruning ###\n",
    "    # row_scores = score_row_tabert(row_chunks, question)\n",
    "    row_scores = score_row_chunks_tabert(question, row_chunks)\n",
    "\n",
    "    for item in row_scores:\n",
    "        print(f\"{item['chunk_id']} → Score: {item['score']}\")\n",
    "\n",
    "    row_scores_only = [chunk[\"score\"] for chunk in row_scores]\n",
    "    alpha = 0.5 #check if this can be learned\n",
    "    row_threshold = dynamic_threshold(row_scores_only, alpha)\n",
    "    print(\"Row Threshold:\", row_threshold)\n",
    "\n",
    "    filtered_row_chunks = filter_chunks_by_row_score(row_chunks, row_scores, row_threshold)\n",
    "\n",
    "    # print(f\"Computing similarity scores... done!\")\n",
    "\n",
    "    filtered_columns_df = column_chunks_to_dataframe(filtered_column_chunks)\n",
    "    filtered_row_df = row_chunks_to_dataframe(filtered_row_chunks)\n",
    "\n",
    "    # print(\"column DF\")\n",
    "    # print(filtered_columns_df)\n",
    "    # print('-' * 80)\n",
    "    # print(\"row DF\")\n",
    "    # print(filtered_row_df)\n",
    "\n",
    "    pruned_df = intersect_row_and_column_dfs(filtered_row_df, filtered_columns_df)\n",
    "\n",
    "    print('-' * 80)\n",
    "    print(\"final DF\")\n",
    "    print(pruned_df)\n",
    "\n",
    "    return pruned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "whUFYkQvNZIF",
    "outputId": "b051deac-5d94-4302-cc37-abcdedb5077a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who is the chief of the gods according to ancient greek myth\n",
      "Loading and filtering chunks for target table...\n",
      "Found 13 chunks that match table ID 'List of pharaohs_A3680D6D69C5E013' out of 2881668 total chunks\n",
      "  Name            → 0.8877\n",
      "  Image           → 0.9160\n",
      "  Comments        → 0.8399\n",
      "  Dates           → 0.8858\n",
      "                  → 0.8339\n",
      "Column Threshold: 0.8795692555821957\n",
      "List of pharaohs_A3680D6D69C5E013_row_0 → Score: 0.8662\n",
      "List of pharaohs_A3680D6D69C5E013_row_1 → Score: 0.879\n",
      "List of pharaohs_A3680D6D69C5E013_row_2 → Score: 0.8642\n",
      "List of pharaohs_A3680D6D69C5E013_row_3 → Score: 0.86\n",
      "List of pharaohs_A3680D6D69C5E013_row_4 → Score: 0.8677\n",
      "List of pharaohs_A3680D6D69C5E013_row_5 → Score: 0.8123\n",
      "List of pharaohs_A3680D6D69C5E013_row_6 → Score: 0.8694\n",
      "List of pharaohs_A3680D6D69C5E013_row_7 → Score: 0.8645\n",
      "Row Threshold: 0.8748020314450123\n",
      "--------------------------------------------------------------------------------\n",
      "final DF\n",
      "          Dates Image   Name\n",
      "0  2589–2566 BC        Khufu\n",
      "Loading and filtering chunks for target table...\n",
      "Found 54 chunks that match table ID 'List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48' out of 2881668 total chunks\n",
      "  Title           → 0.7468\n",
      "  Release date    → 0.8629\n",
      "  Time period     → 0.7881\n",
      "  Notes on setting → 0.7623\n",
      "                  → 0.8114\n",
      "Column Threshold: 0.7799430103592073\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_0 → Score: 0.8708\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_1 → Score: 0.8797\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_2 → Score: 0.8889\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_3 → Score: 0.8755\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_4 → Score: 0.8819\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_5 → Score: 0.8664\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_6 → Score: 0.8727\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_7 → Score: 0.8788\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_8 → Score: 0.8857\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_9 → Score: 0.8905\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_10 → Score: 0.8841\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_11 → Score: 0.8194\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_12 → Score: 0.8832\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_13 → Score: 0.8721\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_14 → Score: 0.8896\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_15 → Score: 0.8903\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_16 → Score: 0.874\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_17 → Score: 0.8878\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_18 → Score: 0.8879\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_19 → Score: 0.8854\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_20 → Score: 0.8932\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_21 → Score: 0.8815\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_22 → Score: 0.874\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_23 → Score: 0.8567\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_24 → Score: 0.8641\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_25 → Score: 0.8593\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_26 → Score: 0.8696\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_27 → Score: 0.8509\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_28 → Score: 0.8744\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_29 → Score: 0.9003\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_30 → Score: 0.8781\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_31 → Score: 0.86\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_32 → Score: 0.8852\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_33 → Score: 0.8606\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_34 → Score: 0.8426\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_35 → Score: 0.8521\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_36 → Score: 0.8728\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_37 → Score: 0.8738\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_38 → Score: 0.8962\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_39 → Score: 0.8892\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_40 → Score: 0.8712\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_41 → Score: 0.8635\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_42 → Score: 0.8645\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_43 → Score: 0.8751\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_44 → Score: 0.8656\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_45 → Score: 0.8759\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_46 → Score: 0.8792\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_47 → Score: 0.8659\n",
      "List of historical period drama films and series set in Near Eastern and Western civilization_AA41E291AC14FC48_row_48 → Score: 0.8783\n",
      "Row Threshold: 0.8823838307174773\n",
      "--------------------------------------------------------------------------------\n",
      "final DF\n",
      "   Release date                                     Time period\n",
      "0          1994  1852–1677 BC(according to the Hebrew calendar)\n",
      "1          1960                                    2589–2566 BC\n",
      "2          1945                                    2558–2532 BC\n",
      "3          2008                                    2270–2215 BC\n",
      "4          2013                                   2000 BC–37 AD\n",
      "5          1995                                 1745 BC–1544 BC\n",
      "6          1954                                         1350 BC\n",
      "7          2015                                    1332–1323 BC\n",
      "8          1956                         c. 15th–13th century BC\n",
      "9          2014                                    1290–1213 BC\n",
      "10         1962                           early 12th century BC\n",
      "11         1966                                         1069 BC\n",
      "12         1953                                      874–853 BC\n",
      "13         1962                                          810 BC\n",
      "Loading and filtering chunks for target table...\n",
      "Found 26 chunks that match table ID 'List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3' out of 2881668 total chunks\n",
      "  Affix           → 0.8390\n",
      "  Meaning         → 0.8384\n",
      "  Origin language and etymology → 0.8653\n",
      "  Example(s)      → 0.8270\n",
      "                  → 0.8565\n",
      "Column Threshold: 0.8362466573042935\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_0 → Score: 0.8992\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_1 → Score: 0.907\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_2 → Score: 0.9118\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_3 → Score: 0.8843\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_4 → Score: 0.8795\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_5 → Score: 0.8848\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_6 → Score: 0.8906\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_7 → Score: 0.8855\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_8 → Score: 0.8957\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_9 → Score: 0.8933\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_10 → Score: 0.9036\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_11 → Score: 0.8911\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_12 → Score: 0.9034\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_13 → Score: 0.9132\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_14 → Score: 0.9138\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_15 → Score: 0.8897\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_16 → Score: 0.913\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_17 → Score: 0.8582\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_18 → Score: 0.9105\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_19 → Score: 0.9041\n",
      "List of medical roots, suffixes and prefixes_A2E6D18E2407DDF3_row_20 → Score: 0.9039\n",
      "Row Threshold: 0.9060032113598842\n",
      "--------------------------------------------------------------------------------\n",
      "final DF\n",
      "               Affix                                            Meaning  \\\n",
      "0         lacrim(o)-                                               tear   \n",
      "1  lact(i)-, lact(o)                                               milk   \n",
      "2           lith(o)-                                    stone, calculus   \n",
      "3            log(o)-                                             speech   \n",
      "4              -logy  Denotes the academic study or practice of a ce...   \n",
      "5          lymph(o)-                                              lymph   \n",
      "\n",
      "       Origin language and etymology  \n",
      "0                              Latin  \n",
      "1                              Latin  \n",
      "2               Greek λίθος (lithos)  \n",
      "3                Greek λόγος (logos)  \n",
      "4  Ancient Greek λόγoς (logos) study  \n",
      "5               Latin lympha - water  \n",
      "Loading and filtering chunks for target table...\n",
      "Found 107 chunks that match table ID 'Monarch_FEA5372160C0FCA6' out of 2881668 total chunks\n",
      "  Region          → 0.6866\n",
      "  Title           → 0.7649\n",
      "  Description and use → 0.8602\n",
      "                  → 0.8282\n",
      "Column Threshold: 0.7832805435303477\n",
      "Monarch_FEA5372160C0FCA6_row_0 → Score: 0.916\n",
      "Monarch_FEA5372160C0FCA6_row_1 → Score: 0.9246\n",
      "Monarch_FEA5372160C0FCA6_row_2 → Score: 0.8988\n",
      "Monarch_FEA5372160C0FCA6_row_3 → Score: 0.9068\n",
      "Monarch_FEA5372160C0FCA6_row_4 → Score: 0.925\n",
      "Monarch_FEA5372160C0FCA6_row_5 → Score: 0.9156\n",
      "Monarch_FEA5372160C0FCA6_row_6 → Score: 0.919\n",
      "Monarch_FEA5372160C0FCA6_row_7 → Score: 0.9192\n",
      "Monarch_FEA5372160C0FCA6_row_8 → Score: 0.9147\n",
      "Monarch_FEA5372160C0FCA6_row_9 → Score: 0.9095\n",
      "Monarch_FEA5372160C0FCA6_row_10 → Score: 0.8826\n",
      "Monarch_FEA5372160C0FCA6_row_11 → Score: 0.9142\n",
      "Monarch_FEA5372160C0FCA6_row_12 → Score: 0.9264\n",
      "Monarch_FEA5372160C0FCA6_row_13 → Score: 0.9205\n",
      "Monarch_FEA5372160C0FCA6_row_14 → Score: 0.9168\n",
      "Monarch_FEA5372160C0FCA6_row_15 → Score: 0.9154\n",
      "Monarch_FEA5372160C0FCA6_row_16 → Score: 0.9144\n",
      "Monarch_FEA5372160C0FCA6_row_17 → Score: 0.8903\n",
      "Monarch_FEA5372160C0FCA6_row_18 → Score: 0.9017\n",
      "Monarch_FEA5372160C0FCA6_row_19 → Score: 0.9124\n",
      "Monarch_FEA5372160C0FCA6_row_20 → Score: 0.9084\n",
      "Monarch_FEA5372160C0FCA6_row_21 → Score: 0.9117\n",
      "Monarch_FEA5372160C0FCA6_row_22 → Score: 0.9075\n",
      "Monarch_FEA5372160C0FCA6_row_23 → Score: 0.9263\n",
      "Monarch_FEA5372160C0FCA6_row_24 → Score: 0.9213\n",
      "Monarch_FEA5372160C0FCA6_row_25 → Score: 0.911\n",
      "Monarch_FEA5372160C0FCA6_row_26 → Score: 0.9093\n",
      "Monarch_FEA5372160C0FCA6_row_27 → Score: 0.9162\n",
      "Monarch_FEA5372160C0FCA6_row_28 → Score: 0.9057\n",
      "Monarch_FEA5372160C0FCA6_row_29 → Score: 0.9233\n",
      "Monarch_FEA5372160C0FCA6_row_30 → Score: 0.9144\n",
      "Monarch_FEA5372160C0FCA6_row_31 → Score: 0.9165\n",
      "Monarch_FEA5372160C0FCA6_row_32 → Score: 0.921\n",
      "Monarch_FEA5372160C0FCA6_row_33 → Score: 0.9005\n",
      "Monarch_FEA5372160C0FCA6_row_34 → Score: 0.9063\n",
      "Monarch_FEA5372160C0FCA6_row_35 → Score: 0.9167\n",
      "Monarch_FEA5372160C0FCA6_row_36 → Score: 0.9128\n",
      "Monarch_FEA5372160C0FCA6_row_37 → Score: 0.9094\n",
      "Monarch_FEA5372160C0FCA6_row_38 → Score: 0.9223\n",
      "Monarch_FEA5372160C0FCA6_row_39 → Score: 0.906\n",
      "Monarch_FEA5372160C0FCA6_row_40 → Score: 0.9133\n",
      "Monarch_FEA5372160C0FCA6_row_41 → Score: 0.8882\n",
      "Monarch_FEA5372160C0FCA6_row_42 → Score: 0.915\n",
      "Monarch_FEA5372160C0FCA6_row_43 → Score: 0.9066\n",
      "Monarch_FEA5372160C0FCA6_row_44 → Score: 0.9032\n",
      "Monarch_FEA5372160C0FCA6_row_45 → Score: 0.9137\n",
      "Monarch_FEA5372160C0FCA6_row_46 → Score: 0.9163\n",
      "Monarch_FEA5372160C0FCA6_row_47 → Score: 0.9001\n",
      "Monarch_FEA5372160C0FCA6_row_48 → Score: 0.9164\n",
      "Monarch_FEA5372160C0FCA6_row_49 → Score: 0.9027\n",
      "Monarch_FEA5372160C0FCA6_row_50 → Score: 0.9064\n",
      "Monarch_FEA5372160C0FCA6_row_51 → Score: 0.9149\n",
      "Monarch_FEA5372160C0FCA6_row_52 → Score: 0.8922\n",
      "Monarch_FEA5372160C0FCA6_row_53 → Score: 0.9161\n",
      "Monarch_FEA5372160C0FCA6_row_54 → Score: 0.8938\n",
      "Monarch_FEA5372160C0FCA6_row_55 → Score: 0.8887\n",
      "Monarch_FEA5372160C0FCA6_row_56 → Score: 0.9092\n",
      "Monarch_FEA5372160C0FCA6_row_57 → Score: 0.915\n",
      "Monarch_FEA5372160C0FCA6_row_58 → Score: 0.9122\n",
      "Monarch_FEA5372160C0FCA6_row_59 → Score: 0.9\n",
      "Monarch_FEA5372160C0FCA6_row_60 → Score: 0.877\n",
      "Monarch_FEA5372160C0FCA6_row_61 → Score: 0.8885\n",
      "Monarch_FEA5372160C0FCA6_row_62 → Score: 0.9089\n",
      "Monarch_FEA5372160C0FCA6_row_63 → Score: 0.8698\n",
      "Monarch_FEA5372160C0FCA6_row_64 → Score: 0.8908\n",
      "Monarch_FEA5372160C0FCA6_row_65 → Score: 0.931\n",
      "Monarch_FEA5372160C0FCA6_row_66 → Score: 0.8973\n",
      "Monarch_FEA5372160C0FCA6_row_67 → Score: 0.9208\n",
      "Monarch_FEA5372160C0FCA6_row_68 → Score: 0.9065\n",
      "Monarch_FEA5372160C0FCA6_row_69 → Score: 0.9124\n",
      "Monarch_FEA5372160C0FCA6_row_70 → Score: 0.8983\n",
      "Monarch_FEA5372160C0FCA6_row_71 → Score: 0.9091\n",
      "Monarch_FEA5372160C0FCA6_row_72 → Score: 0.9022\n",
      "Monarch_FEA5372160C0FCA6_row_73 → Score: 0.8993\n",
      "Monarch_FEA5372160C0FCA6_row_74 → Score: 0.9125\n",
      "Monarch_FEA5372160C0FCA6_row_75 → Score: 0.9008\n",
      "Monarch_FEA5372160C0FCA6_row_76 → Score: 0.9219\n",
      "Monarch_FEA5372160C0FCA6_row_77 → Score: 0.9181\n",
      "Monarch_FEA5372160C0FCA6_row_78 → Score: 0.8912\n",
      "Monarch_FEA5372160C0FCA6_row_79 → Score: 0.9072\n",
      "Monarch_FEA5372160C0FCA6_row_80 → Score: 0.8795\n",
      "Monarch_FEA5372160C0FCA6_row_81 → Score: 0.9059\n",
      "Monarch_FEA5372160C0FCA6_row_82 → Score: 0.9076\n",
      "Monarch_FEA5372160C0FCA6_row_83 → Score: 0.8985\n",
      "Monarch_FEA5372160C0FCA6_row_84 → Score: 0.9099\n",
      "Monarch_FEA5372160C0FCA6_row_85 → Score: 0.8735\n",
      "Monarch_FEA5372160C0FCA6_row_86 → Score: 0.9105\n",
      "Monarch_FEA5372160C0FCA6_row_87 → Score: 0.9034\n",
      "Monarch_FEA5372160C0FCA6_row_88 → Score: 0.8982\n",
      "Monarch_FEA5372160C0FCA6_row_89 → Score: 0.9092\n",
      "Monarch_FEA5372160C0FCA6_row_90 → Score: 0.9061\n",
      "Monarch_FEA5372160C0FCA6_row_91 → Score: 0.8987\n",
      "Monarch_FEA5372160C0FCA6_row_92 → Score: 0.9116\n",
      "Monarch_FEA5372160C0FCA6_row_93 → Score: 0.9132\n",
      "Monarch_FEA5372160C0FCA6_row_94 → Score: 0.9131\n",
      "Monarch_FEA5372160C0FCA6_row_95 → Score: 0.9172\n",
      "Monarch_FEA5372160C0FCA6_row_96 → Score: 0.9154\n",
      "Monarch_FEA5372160C0FCA6_row_97 → Score: 0.9108\n",
      "Monarch_FEA5372160C0FCA6_row_98 → Score: 0.9141\n",
      "Monarch_FEA5372160C0FCA6_row_99 → Score: 0.9009\n",
      "Monarch_FEA5372160C0FCA6_row_100 → Score: 0.903\n",
      "Monarch_FEA5372160C0FCA6_row_101 → Score: 0.8975\n",
      "Monarch_FEA5372160C0FCA6_row_102 → Score: 0.9062\n",
      "Row Threshold: 0.9151545536195077\n",
      "--------------------------------------------------------------------------------\n",
      "final DF\n",
      "                                  Description and use\n",
      "0                        Fulani people of west Africa\n",
      "1    Title of the king of the Ashanti people in Ghana\n",
      "2                                  Leader of a people\n",
      "3                              Igbo people of Nigeria\n",
      "4   Baganda people of Buganda in Uganda Mangi for ...\n",
      "5                                     King of Morocco\n",
      "6              Bunyoro, title of some kings in Uganda\n",
      "7                            Emperor of Ancient Egypt\n",
      "8                            King of the Hausa people\n",
      "9   Title of the ruler of the Swat in present-day ...\n",
      "10   Honorary title of the leaders in the Philippines\n",
      "11                  Limbu King of East Nepal Limbuwan\n",
      "12       皇帝 as in Chinese, the Imperial China Emperor\n",
      "13  title used by the rulers of the Kingdom of Ton...\n",
      "14                        Used in India and Sri Lanka\n",
      "15                     Used in Andhra Pradesh (India)\n",
      "16                          Used in Hyderabad (India)\n",
      "17                                Sub- king Sri lanka\n",
      "18   Used in northern and western India, Yaduvanshis.\n",
      "19     Shan, king of Shan, today as a part of Myanmar\n",
      "20                                        Japan, king\n",
      "21                     \"King\" during Mycenaean Greece\n",
      "22    Greek term for the Roman and Byzantine Emperors\n",
      "23                       The Ruler of Imperial Russia\n",
      "24  Medieval Romanian title \"Io\" derived from the ...\n",
      "25  King of Ancient Israel (e.g. Saul, David and S...\n",
      "26       Arabic King, (Saudi Arabia, Bahrain, Jordan)\n",
      "Loading and filtering chunks for target table...\n",
      "Found 33 chunks that match table ID 'Olympian Gods (DC Comics)_DE50A89336AE7CAE' out of 2881668 total chunks\n",
      "  Member          → 0.8322\n",
      "  First appearance → 0.6882\n",
      "  Description     → 0.6823\n",
      "                  → 0.7019\n",
      "Column Threshold: 0.682722108858365\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_0 → Score: 0.7175\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_1 → Score: 0.8406\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_2 → Score: 0.8578\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_3 → Score: 0.7941\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_4 → Score: 0.8234\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_5 → Score: 0.7824\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_6 → Score: 0.8122\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_7 → Score: 0.7884\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_8 → Score: 0.8573\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_9 → Score: 0.8357\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_10 → Score: 0.824\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_11 → Score: 0.8238\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_12 → Score: 0.8544\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_13 → Score: 0.7819\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_14 → Score: 0.8021\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_15 → Score: 0.8011\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_16 → Score: 0.8338\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_17 → Score: 0.7743\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_18 → Score: 0.8632\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_19 → Score: 0.8831\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_20 → Score: 0.8809\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_21 → Score: 0.874\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_22 → Score: 0.8692\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_23 → Score: 0.8627\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_24 → Score: 0.8482\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_25 → Score: 0.8173\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_26 → Score: 0.8426\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_27 → Score: 0.8494\n",
      "Olympian Gods (DC Comics)_DE50A89336AE7CAE_row_28 → Score: 0.7868\n",
      "Row Threshold: 0.8526828918032632\n",
      "--------------------------------------------------------------------------------\n",
      "final DF\n",
      "                          First appearance      Member\n",
      "0           National Comics #1 (July 1940)        Ares\n",
      "1         Wonder Woman #45 (December 2015)      Eirene\n",
      "2             Wonder Woman #2 (March 1987)    Harmonia\n",
      "3          Wonder Woman #1 (February 1987)      Hestia\n",
      "4          Wonder Woman #140 (August 1963)    Morpheus\n",
      "5            Wonder Woman #611 (July 2011)     Nemesis\n",
      "6             Batwoman #13 (December 2012)         Nyx\n",
      "7  The Fury of Firestorm #5 (October 1985)         Pan\n",
      "8              Wonder Woman #5 (June 1987)  Persephone\n",
      "Loading and filtering chunks for target table...\n",
      "Found 15 chunks that match table ID 'Flags of Europe_B0E3EF092429C8AA' out of 2881668 total chunks\n",
      "  Flag            → 0.8953\n",
      "  Date            → 0.8841\n",
      "  Use             → 0.8759\n",
      "  Description     → 0.7888\n",
      "                  → 0.8144\n",
      "Column Threshold: 0.8674695504271718\n",
      "Flags of Europe_B0E3EF092429C8AA_row_0 → Score: 0.8879\n",
      "Flags of Europe_B0E3EF092429C8AA_row_1 → Score: 0.8777\n",
      "Flags of Europe_B0E3EF092429C8AA_row_2 → Score: 0.8482\n",
      "Flags of Europe_B0E3EF092429C8AA_row_3 → Score: 0.8613\n",
      "Flags of Europe_B0E3EF092429C8AA_row_4 → Score: 0.8808\n",
      "Flags of Europe_B0E3EF092429C8AA_row_5 → Score: 0.8673\n",
      "Flags of Europe_B0E3EF092429C8AA_row_6 → Score: 0.8687\n",
      "Flags of Europe_B0E3EF092429C8AA_row_7 → Score: 0.8528\n",
      "Flags of Europe_B0E3EF092429C8AA_row_8 → Score: 0.8373\n",
      "Flags of Europe_B0E3EF092429C8AA_row_9 → Score: 0.8546\n",
      "Row Threshold: 0.8718109653174542\n",
      "--------------------------------------------------------------------------------\n",
      "final DF\n",
      "      Date Flag                         Use\n",
      "0  1900s –              Flag of Mount Athos\n",
      "1  1980s –       Flag of Macedonia (Greece)\n",
      "2   1821 –                    Flag of Hydra\n",
      "Loading and filtering chunks for target table...\n",
      "Found 143 chunks that match table ID 'List of chemical element name etymologies_41934D70E87D313A' out of 2881668 total chunks\n",
      "  Element         → 0.8780\n",
      "  Element.1       → 0.7859\n",
      "  Element.2       → 0.7796\n",
      "  Language of origin → 0.7923\n",
      "  Original word   → 0.8156\n",
      "  Meaning         → 0.8496\n",
      "  Symbol origin   → 0.7880\n",
      "  Description     → 0.8668\n",
      "                  → 0.8174\n",
      "Column Threshold: 0.8085959877459901\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_0 → Score: 0.8898\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_1 → Score: 0.8484\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_2 → Score: 0.8471\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_3 → Score: 0.8877\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_4 → Score: 0.807\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_5 → Score: 0.8898\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_6 → Score: 0.8898\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_7 → Score: 0.8228\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_8 → Score: 0.8394\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_9 → Score: 0.8726\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_10 → Score: 0.855\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_11 → Score: 0.8759\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_12 → Score: 0.8695\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_13 → Score: 0.8432\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_14 → Score: 0.8386\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_15 → Score: 0.872\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_16 → Score: 0.8744\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_17 → Score: 0.8726\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_18 → Score: 0.8299\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_19 → Score: 0.8428\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_20 → Score: 0.8553\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_21 → Score: 0.7823\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_22 → Score: 0.8832\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_23 → Score: 0.8674\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_24 → Score: 0.8584\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_25 → Score: 0.8354\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_26 → Score: 0.8726\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_27 → Score: 0.8577\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_28 → Score: 0.839\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_29 → Score: 0.8419\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_30 → Score: 0.8117\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_31 → Score: 0.8736\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_32 → Score: 0.8634\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_33 → Score: 0.8792\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_34 → Score: 0.8607\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_35 → Score: 0.8726\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_36 → Score: 0.8686\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_37 → Score: 0.838\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_38 → Score: 0.8727\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_39 → Score: 0.8559\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_40 → Score: 0.8626\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_41 → Score: 0.875\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_42 → Score: 0.8866\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_43 → Score: 0.8718\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_44 → Score: 0.8539\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_45 → Score: 0.853\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_46 → Score: 0.8726\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_47 → Score: 0.86\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_48 → Score: 0.8747\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_49 → Score: 0.8627\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_50 → Score: 0.821\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_51 → Score: 0.8815\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_52 → Score: 0.8438\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_53 → Score: 0.842\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_54 → Score: 0.839\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_55 → Score: 0.8288\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_56 → Score: 0.866\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_57 → Score: 0.8541\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_58 → Score: 0.8558\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_59 → Score: 0.8726\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_60 → Score: 0.8611\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_61 → Score: 0.8655\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_62 → Score: 0.8639\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_63 → Score: 0.8718\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_64 → Score: 0.8868\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_65 → Score: 0.8719\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_66 → Score: 0.8466\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_67 → Score: 0.8697\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_68 → Score: 0.8281\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_69 → Score: 0.8093\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_70 → Score: 0.8726\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_71 → Score: 0.8418\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_72 → Score: 0.8707\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_73 → Score: 0.849\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_74 → Score: 0.8598\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_75 → Score: 0.8742\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_76 → Score: 0.8567\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_77 → Score: 0.8545\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_78 → Score: 0.8646\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_79 → Score: 0.8337\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_80 → Score: 0.8629\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_81 → Score: 0.854\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_82 → Score: 0.8415\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_83 → Score: 0.8741\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_84 → Score: 0.8389\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_85 → Score: 0.8726\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_86 → Score: 0.865\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_87 → Score: 0.8272\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_88 → Score: 0.8022\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_89 → Score: 0.876\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_90 → Score: 0.8588\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_91 → Score: 0.8614\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_92 → Score: 0.8693\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_93 → Score: 0.8559\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_94 → Score: 0.8724\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_95 → Score: 0.8741\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_96 → Score: 0.875\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_97 → Score: 0.864\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_98 → Score: 0.872\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_99 → Score: 0.8726\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_100 → Score: 0.8537\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_101 → Score: 0.8367\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_102 → Score: 0.8694\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_103 → Score: 0.8768\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_104 → Score: 0.8733\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_105 → Score: 0.8835\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_106 → Score: 0.8748\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_107 → Score: 0.8474\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_108 → Score: 0.8358\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_109 → Score: 0.8534\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_110 → Score: 0.8898\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_111 → Score: 0.8898\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_112 → Score: 0.8726\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_113 → Score: 0.8835\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_114 → Score: 0.8366\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_115 → Score: 0.8071\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_116 → Score: 0.8516\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_117 → Score: 0.8641\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_118 → Score: 0.8569\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_119 → Score: 0.8796\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_120 → Score: 0.846\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_121 → Score: 0.8375\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_122 → Score: 0.8726\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_123 → Score: 0.874\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_124 → Score: 0.8821\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_125 → Score: 0.8547\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_126 → Score: 0.8613\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_127 → Score: 0.8555\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_128 → Score: 0.88\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_129 → Score: 0.8607\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_130 → Score: 0.8745\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_131 → Score: 0.8728\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_132 → Score: 0.8811\n",
      "List of chemical element name etymologies_41934D70E87D313A_row_133 → Score: 0.857\n",
      "Row Threshold: 0.8728649713542893\n",
      "--------------------------------------------------------------------------------\n",
      "final DF\n",
      "                                         Description Element Meaning  \\\n",
      "0  Borrowed from a Proto-Indo-European language, ...      50           \n",
      "\n",
      "  Original word  \n",
      "0           tin  \n",
      "Loading and filtering chunks for target table...\n",
      "Found 16 chunks that match table ID 'Olympian Gods (DC Comics)_82CC97B123F8ACC0' out of 2881668 total chunks\n",
      "  [hide] v t e Wonder Woman → 0.8767\n",
      "  [hide] v t e Wonder Woman.1 → 0.7278\n",
      "                  → 0.7072\n",
      "Column Threshold: 0.7126965316713162\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_0 → Score: 0.8381\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_1 → Score: 0.6612\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_2 → Score: 0.8918\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_3 → Score: 0.8482\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_4 → Score: 0.7971\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_5 → Score: 0.801\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_6 → Score: 0.8861\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_7 → Score: 0.8135\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_8 → Score: 0.8563\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_9 → Score: 0.9054\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_10 → Score: 0.8469\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_11 → Score: 0.8883\n",
      "Olympian Gods (DC Comics)_82CC97B123F8ACC0_row_12 → Score: 0.8822\n",
      "Row Threshold: 0.8790892002536111\n",
      "--------------------------------------------------------------------------------\n",
      "final DF\n",
      "  [hide] v t e Wonder Woman                        [hide] v t e Wonder Woman.1\n",
      "0              Wonder Women  Diana Prince Orana Artemis of Bana-Mighdall Hi...\n",
      "1                 Locations  Aeaea Boston, Massachusetts London, England Mo...\n",
      "2                Technology  Bracelets Golden Girdle of Gaea Invisible plan...\n",
      "3             Miscellaneous  Alternative versions Earth-Two Bizarra Olive B...\n",
      "4          Portal  Category                                   Portal  Category\n",
      "Loading and filtering chunks for target table...\n",
      "Found 23 chunks that match table ID 'The Magicians (U.S. TV series)_C1761A0BEB4A7B16' out of 2881668 total chunks\n",
      "  No. overall     → 0.7832\n",
      "  No. in season   → 0.7762\n",
      "  Title           → 0.7556\n",
      "  Directed by     → 0.7801\n",
      "  Written by      → 0.7750\n",
      "  Original air date → 0.7755\n",
      "  U.S. viewers (millions) → 0.7517\n",
      "                  → 0.6821\n",
      "Column Threshold: 0.7689943805262788\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_0 → Score: 0.8536\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_1 → Score: 0.7132\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_2 → Score: 0.8493\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_3 → Score: 0.8554\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_4 → Score: 0.8552\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_5 → Score: 0.8625\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_6 → Score: 0.8678\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_7 → Score: 0.8647\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_8 → Score: 0.8645\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_9 → Score: 0.8609\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_10 → Score: 0.87\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_11 → Score: 0.8706\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_12 → Score: 0.8579\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_13 → Score: 0.8591\n",
      "The Magicians (U.S. TV series)_C1761A0BEB4A7B16_row_14 → Score: 0.6936\n",
      "Row Threshold: 0.8860871813192033\n",
      "⚠️ No overlapping columns found between the DataFrames.\n",
      "--------------------------------------------------------------------------------\n",
      "final DF\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Loading and filtering chunks for target table...\n",
      "Found 16 chunks that match table ID 'Wonder Woman (TV series)_C16AF4AAF0089316' out of 2881668 total chunks\n",
      "  showvteWonder Woman → 0.8820\n",
      "  showvteWonder Woman.1 → 0.7573\n",
      "                  → 0.7327\n",
      "Column Threshold: 0.7442282764887121\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_0 → Score: 0.8544\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_1 → Score: 0.6732\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_2 → Score: 0.8994\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_3 → Score: 0.8524\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_4 → Score: 0.7949\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_5 → Score: 0.8222\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_6 → Score: 0.8699\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_7 → Score: 0.8096\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_8 → Score: 0.8549\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_9 → Score: 0.9103\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_10 → Score: 0.8935\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_11 → Score: 0.8887\n",
      "Wonder Woman (TV series)_C16AF4AAF0089316_row_12 → Score: 0.8956\n",
      "Row Threshold: 0.8854765800658071\n",
      "--------------------------------------------------------------------------------\n",
      "final DF\n",
      "  showvteWonder Woman                              showvteWonder Woman.1\n",
      "0        Wonder Women  Diana Prince Orana Artemis of Bana-Mighdall Hi...\n",
      "1          Technology  Bracelets Golden Girdle of Gaea Invisible plan...\n",
      "2      In other media  Wonder Woman (1974 film) Wonder Woman (TV seri...\n",
      "3       Miscellaneous  Alternative versions Earth-Two Bizarra Olive B...\n",
      "4    Portal  Category                                   Portal  Category\n",
      "Execution time: 136.0418 seconds\n"
     ]
    }
   ],
   "source": [
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Determine which table ID to use\n",
    "    query_csv = \"query6_TopTables.csv\"\n",
    "    query_csv_df = pd.read_csv(query_csv)\n",
    "    question = query_csv_df['query'][0]\n",
    "    print(question)\n",
    "    table_list = query_csv_df['top tables'].tolist()\n",
    "    target_table_id = query_csv_df['target table'][0]\n",
    "    goal_answer = query_csv_df['target answer'][0]\n",
    "\n",
    "    # all_entries = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    with open(\"all_pruned_tables_tabert.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for table_id in table_list[:10]:\n",
    "\n",
    "            pruned_df = prune_table(table_id, question)\n",
    "\n",
    "            if not pruned_df.empty:\n",
    "                entry = dataframe_to_json_entry(pruned_df,table_id)\n",
    "                f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Execution time: {end_time - start_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TN4BqRBQPXzL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
